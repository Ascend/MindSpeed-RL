diff --git a/mbridge/models/ext/deepseek_v3/dequant_fp8_safetensor_io.py b/mbridge/models/ext/deepseek_v3/dequant_fp8_safetensor_io.py
index 5012942..6d66046 100644
--- a/mbridge/models/ext/deepseek_v3/dequant_fp8_safetensor_io.py
+++ b/mbridge/models/ext/deepseek_v3/dequant_fp8_safetensor_io.py
@@ -9,6 +9,7 @@ import torch
 from safetensors import safe_open
 
 from mbridge.core.safetensor_io import SafeTensorIO
+from mbridge.utils.device import get_device_name
 
 from .kernel import weight_dequant
 
@@ -31,7 +32,7 @@ class DequantFP8SafeTensorIO(SafeTensorIO):
             file_to_weight_map[filename].append(name)
         for filename, weight_names in file_to_weight_map.items():
             safetensor_file = os.path.join(hf_dir, filename)
-            with safe_open(safetensor_file, framework="pt", device="cuda") as f:
+            with safe_open(safetensor_file, framework="pt", device=get_device_name()) as f:
                 for name in weight_names:
                     weight = f.get_tensor(name)
                     scale_inv_name = f"{name}_scale_inv"
@@ -48,7 +49,7 @@ class DequantFP8SafeTensorIO(SafeTensorIO):
                                         hf_dir, weight_to_file_map[scale_inv_name]
                                     ),
                                     framework="pt",
-                                    device="cuda",
+                                    device=get_device_name(),
                                 ) as f2:
                                     scale_inv = f2.get_tensor(scale_inv_name)
                             ret[name] = weight_dequant(weight, scale_inv)

diff --git a/mbridge/models/deepseek_v3.py b/mbridge/models/deepseek_v3.py
index 478798d..83127ce 100644
--- a/mbridge/models/deepseek_v3.py
+++ b/mbridge/models/deepseek_v3.py
@@ -242,7 +242,7 @@ class DeepseekV3Bridge(LLMBridge):
                     self.config,
                     transformer_layer_spec_for_mtp,
                     use_transformer_engine=True,
-                    vp_stage=vp_stage,
+                    # vp_stage=vp_stage,
                 )
                 gptmodel_args["mtp_block_spec"] = mtp_block_spec
                 print(f"mtp_block_spec: {mtp_block_spec}")
