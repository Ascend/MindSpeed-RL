diff --git a/recipe/dapo/dapo_ray_trainer.py b/recipe/dapo/dapo_ray_trainer.py
index 18995f67..db209482 100644
--- a/recipe/dapo/dapo_ray_trainer.py
+++ b/recipe/dapo/dapo_ray_trainer.py
@@ -156,7 +156,7 @@ class RayDAPOTrainer(RayPPOTrainer):
                         non_tensor_batch_keys=["raw_prompt_ids"],
                     )
                 gen_batch_output = gen_batch.repeat(
-                    repeat_times=self.config.actor_rollout_ref.rollout.n, interleave=True
+                    repeat_times=self.config.actor_rollout_ref.rollout.n, interleave=False
                 )
 
                 is_last_step = self.global_steps >= self.total_training_steps
@@ -196,7 +196,7 @@ class RayDAPOTrainer(RayPPOTrainer):
                         [str(uuid.uuid4()) for _ in range(len(new_batch.batch))], dtype=object
                     )
                     # repeat to align with repeated responses in rollout
-                    new_batch = new_batch.repeat(repeat_times=self.config.actor_rollout_ref.rollout.n, interleave=True)
+                    new_batch = new_batch.repeat(repeat_times=self.config.actor_rollout_ref.rollout.n, interleave=False)
                     new_batch = new_batch.union(gen_batch_output)
 
                     if self.config.algorithm.use_kl_in_reward: